{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('为什么', 0.8298794627189636),\n",
       " ('问', 0.8270461559295654),\n",
       " ('说道', 0.8173126578330994),\n",
       " ('为何', 0.8128331899642944),\n",
       " ('告诉', 0.7882134318351746),\n",
       " ('吗', 0.7878919839859009),\n",
       " ('的话', 0.7855218648910522),\n",
       " ('所说', 0.7767419219017029),\n",
       " ('觉得', 0.7696527242660522),\n",
       " ('讲', 0.7678855657577515),\n",
       " ('怎么样', 0.7658766508102417),\n",
       " ('声称', 0.764196515083313),\n",
       " ('以为', 0.7633250951766968),\n",
       " ('问道', 0.7630106210708618),\n",
       " ('认为', 0.758924126625061),\n",
       " ('中说', 0.751205325126648),\n",
       " ('时说', 0.7498580813407898),\n",
       " ('写道', 0.7494862079620361),\n",
       " ('告诫', 0.7469834089279175),\n",
       " ('说起', 0.7460322380065918),\n",
       " ('确信', 0.7414821982383728),\n",
       " ('质问', 0.7364925146102905),\n",
       " ('谈论', 0.7361835241317749),\n",
       " ('感叹', 0.7359782457351685),\n",
       " ('说出', 0.7354288101196289),\n",
       " ('谁', 0.7353894710540771),\n",
       " ('称', 0.7324063181877136),\n",
       " ('却说', 0.7310951948165894),\n",
       " ('也许', 0.7306363582611084),\n",
       " ('或许', 0.730185866355896)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "model_file = \"zh_word2vec.model\"\n",
    "model = Word2Vec.load(model_file)\n",
    "\n",
    "model.wv.most_similar(\"说\", topn=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_chinese = pd.read_csv(\"/home/weiliang/news_chinese_201908201131.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news_chinese.content.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import jieba\n",
    "def clean(news_text):\n",
    "    text_only = ''.join(re.findall(r'\\w+', news_text)) # only retain valid words\n",
    "    return text_only.replace('n', '') # remove n in news\n",
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.030 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70173\n"
     ]
    }
   ],
   "source": [
    "news_clean = [' '.join(cut(clean(n))) for n in news]\n",
    "news_news_clean_len = len(news_clean)\n",
    "print(news_news_clean_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11877241\n"
     ]
    }
   ],
   "source": [
    "word_total = sum([len(nc.split()) for nc in news_clean])\n",
    "print(word_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chinese_news.corps', 'a+') as f:\n",
    "    for nc in news_clean:\n",
    "        f.write(nc + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LineSentence('chinese_news.corps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec(sentences, size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('表示', 0.8463233709335327),\n",
       " ('认为', 0.7879735231399536),\n",
       " ('指出', 0.7721938490867615),\n",
       " ('告诉', 0.7540926337242126),\n",
       " ('说完', 0.715735673904419),\n",
       " ('看来', 0.6958412528038025),\n",
       " ('称', 0.6870326995849609),\n",
       " ('介绍', 0.6813185214996338),\n",
       " ('坦言', 0.6690934896469116),\n",
       " ('透露', 0.6331932544708252),\n",
       " ('中说', 0.6209747791290283),\n",
       " ('明说', 0.584187388420105),\n",
       " ('罗恩费伦', 0.5742655992507935),\n",
       " ('所说', 0.5712404251098633),\n",
       " ('强调', 0.5711138248443604),\n",
       " ('时说', 0.5316095948219299),\n",
       " ('建议', 0.5299563407897949),\n",
       " ('文说', 0.5233355760574341),\n",
       " ('写道', 0.4978210926055908),\n",
       " ('温德姆', 0.49491986632347107)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar('说', topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model with chinsese news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49138219, 59386205)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"wiki_and_chinese_news_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('表示', 0.8655452132225037),\n",
       " ('告诉', 0.8081321120262146),\n",
       " ('认为', 0.8065691590309143),\n",
       " ('指出', 0.7971088886260986),\n",
       " ('说完', 0.7543131113052368),\n",
       " ('介绍', 0.6950348615646362),\n",
       " ('坦言', 0.6608978509902954),\n",
       " ('称', 0.6517000198364258),\n",
       " ('看来', 0.6478255987167358),\n",
       " ('时说', 0.6423693895339966),\n",
       " ('强调', 0.6018719673156738),\n",
       " ('中说', 0.5731960535049438),\n",
       " ('透露', 0.5685068964958191),\n",
       " ('相信', 0.5671338438987732),\n",
       " ('所说', 0.5622093677520752),\n",
       " ('深信', 0.5584651231765747),\n",
       " ('并不认为', 0.5563322305679321),\n",
       " ('的话', 0.5453881025314331),\n",
       " ('写道', 0.5218533277511597),\n",
       " ('形容', 0.5168880224227905),\n",
       " ('坚信', 0.5134227871894836),\n",
       " ('還說', 0.50819993019104),\n",
       " ('認为', 0.5064188241958618),\n",
       " ('明白', 0.5037347078323364),\n",
       " ('認為', 0.5025042295455933),\n",
       " ('确信', 0.5017237663269043),\n",
       " ('深知', 0.5001986622810364),\n",
       " ('建议', 0.4999033808708191),\n",
       " ('说道', 0.49879705905914307),\n",
       " ('问', 0.496876060962677)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"说\", topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def most_similar(start_word, max_layer=3):\n",
    "    word_paths = [[start_word]]\n",
    "    occurences = defaultdict(int)\n",
    "    searched_words = {}\n",
    "    similar_words_in_layers = [start_word]\n",
    "    while True:\n",
    "        if len(word_paths) > 0:\n",
    "            word_path = word_paths.pop(0)\n",
    "        else:\n",
    "            return occurences\n",
    "        word = word_path[-1]\n",
    "        if word in searched_words:\n",
    "            similar_words = searched_words[word]\n",
    "            \n",
    "        else:\n",
    "            similar_words_with_possibility = model.wv.most_similar(word, topn=30)\n",
    "            similar_words = [word for word, posibility in similar_words_with_possibility]\n",
    "        for similar_word in similar_words:\n",
    "            if start_word == similar_word:\n",
    "                if word not in similar_words_in_layers:\n",
    "                    #similar_words_in_layers.append(word)\n",
    "                    for word in word_path:\n",
    "                        occurences[word] += 1\n",
    "            else:\n",
    "                new_word_path = word_path+[similar_word]\n",
    "                if similar_word not in word_path and len(new_word_path) <= max_layer:\n",
    "                    word_paths.append(new_word_path)\n",
    "                \n",
    "        searched_words[word] = similar_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_words = most_similar(\"说\", 3)\n",
    "from collections import Counter\n",
    "counter = Counter(most_similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('说', 171),\n",
       " ('认为', 30),\n",
       " ('表示', 28),\n",
       " ('告诉', 27),\n",
       " ('指出', 27),\n",
       " ('看来', 22),\n",
       " ('说完', 21),\n",
       " ('时说', 20),\n",
       " ('坦言', 19),\n",
       " ('强调', 17),\n",
       " ('中说', 17),\n",
       " ('介绍', 16),\n",
       " ('称', 16),\n",
       " ('透露', 15),\n",
       " ('所说', 12),\n",
       " ('相信', 10),\n",
       " ('建议', 10),\n",
       " ('的话', 5),\n",
       " ('形容', 2),\n",
       " ('写道', 2)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('表示', 0.8655452132225037),\n",
       " ('告诉', 0.8081321120262146),\n",
       " ('认为', 0.8065691590309143),\n",
       " ('指出', 0.7971088886260986),\n",
       " ('说完', 0.7543131113052368),\n",
       " ('介绍', 0.6950348615646362),\n",
       " ('坦言', 0.6608978509902954),\n",
       " ('称', 0.6517000198364258),\n",
       " ('看来', 0.6478255987167358),\n",
       " ('时说', 0.6423693895339966),\n",
       " ('强调', 0.6018719673156738),\n",
       " ('中说', 0.5731960535049438),\n",
       " ('透露', 0.5685068964958191),\n",
       " ('相信', 0.5671338438987732),\n",
       " ('所说', 0.5622093677520752),\n",
       " ('深信', 0.5584651231765747),\n",
       " ('并不认为', 0.5563322305679321),\n",
       " ('的话', 0.5453881025314331),\n",
       " ('写道', 0.5218533277511597),\n",
       " ('形容', 0.5168880224227905)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"说\", topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use standford CoreNLP to parse news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Requirement already satisfied: stanford-corenlp in /Users/weiliang/anaconda3/lib/python3.7/site-packages (3.9.2)\n",
      "Requirement already satisfied: six>=1.9 in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from stanford-corenlp) (1.12.0)\n",
      "Requirement already satisfied: corenlp-protobuf>=3.8.0 in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from stanford-corenlp) (3.8.0)\n",
      "Requirement already satisfied: requests>=2.10.0 in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from stanford-corenlp) (2.21.0)\n",
      "Requirement already satisfied: protobuf in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from corenlp-protobuf>=3.8.0->stanford-corenlp) (3.9.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from requests>=2.10.0->stanford-corenlp) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from requests>=2.10.0->stanford-corenlp) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from requests>=2.10.0->stanford-corenlp) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from requests>=2.10.0->stanford-corenlp) (2018.11.29)\n",
      "Requirement already satisfied: setuptools in /Users/weiliang/anaconda3/lib/python3.7/site-packages (from protobuf->corenlp-protobuf>=3.8.0->stanford-corenlp) (40.6.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install stanford-corenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CORENLP_HOME\"] = \"/Users/weiliang/Code/AI/nlp/project1/stanford-corenlp-full-2018-10-05/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 1, 'basicDependencies': [{'dep': 'ROOT', 'governor': 0, 'governorGloss': 'ROOT', 'dependent': 4, 'dependentGloss': '情况'}, {'dep': 'nsubj', 'governor': 4, 'governorGloss': '情况', 'dependent': 1, 'dependentGloss': '这'}, {'dep': 'cop', 'governor': 4, 'governorGloss': '情况', 'dependent': 2, 'dependentGloss': '是'}, {'dep': 'det', 'governor': 4, 'governorGloss': '情况', 'dependent': 3, 'dependentGloss': '什么'}, {'dep': 'punct', 'governor': 4, 'governorGloss': '情况', 'dependent': 5, 'dependentGloss': '。'}], 'enhancedDependencies': [{'dep': 'ROOT', 'governor': 0, 'governorGloss': 'ROOT', 'dependent': 4, 'dependentGloss': '情况'}, {'dep': 'nsubj', 'governor': 4, 'governorGloss': '情况', 'dependent': 1, 'dependentGloss': '这'}, {'dep': 'cop', 'governor': 4, 'governorGloss': '情况', 'dependent': 2, 'dependentGloss': '是'}, {'dep': 'det', 'governor': 4, 'governorGloss': '情况', 'dependent': 3, 'dependentGloss': '什么'}, {'dep': 'punct', 'governor': 4, 'governorGloss': '情况', 'dependent': 5, 'dependentGloss': '。'}], 'enhancedPlusPlusDependencies': [{'dep': 'ROOT', 'governor': 0, 'governorGloss': 'ROOT', 'dependent': 4, 'dependentGloss': '情况'}, {'dep': 'nsubj', 'governor': 4, 'governorGloss': '情况', 'dependent': 1, 'dependentGloss': '这'}, {'dep': 'cop', 'governor': 4, 'governorGloss': '情况', 'dependent': 2, 'dependentGloss': '是'}, {'dep': 'det', 'governor': 4, 'governorGloss': '情况', 'dependent': 3, 'dependentGloss': '什么'}, {'dep': 'punct', 'governor': 4, 'governorGloss': '情况', 'dependent': 5, 'dependentGloss': '。'}], 'entitymentions': [], 'tokens': [{'index': 1, 'word': '这', 'originalText': '这', 'lemma': '这', 'characterOffsetBegin': 21, 'characterOffsetEnd': 22, 'pos': 'PN', 'ner': 'O'}, {'index': 2, 'word': '是', 'originalText': '是', 'lemma': '是', 'characterOffsetBegin': 22, 'characterOffsetEnd': 23, 'pos': 'VC', 'ner': 'O'}, {'index': 3, 'word': '什么', 'originalText': '什么', 'lemma': '什么', 'characterOffsetBegin': 23, 'characterOffsetEnd': 25, 'pos': 'DT', 'ner': 'O'}, {'index': 4, 'word': '情况', 'originalText': '情况', 'lemma': '情况', 'characterOffsetBegin': 25, 'characterOffsetEnd': 27, 'pos': 'NN', 'ner': 'O'}, {'index': 5, 'word': '。', 'originalText': '。', 'lemma': '。', 'characterOffsetBegin': 27, 'characterOffsetEnd': 28, 'pos': 'PU', 'ner': 'O'}]}\n"
     ]
    }
   ],
   "source": [
    "import corenlp\n",
    "\n",
    "text = \"奥巴马说这个种事情怎么可以浪费这么多时间。这是什么情况。\"\n",
    "\n",
    "# We assume that you've downloaded Stanford CoreNLP and defined an environment\n",
    "# variable $CORENLP_HOME that points to the unzipped directory.\n",
    "# The code below will launch StanfordCoreNLPServer in the background\n",
    "# and communicate with the server to annotate the sentence.\n",
    "with corenlp.CoreNLPClient(start_server=True,annotators=\"tokenize ssplit ner depparse\".split(), output_format=\"json\") as client:\n",
    "  ann = client.annotate(text)\n",
    "\n",
    "# You can access annotations using ann.\n",
    "#sentence = ann.sentence[0]\n",
    "print(ann['sentences'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'basicDependencies': [{'dep': 'ROOT', 'governor': 0, 'governorGloss': 'ROOT', 'dependent': 2, 'dependentGloss': '说'}, {'dep': 'nsubj', 'governor': 2, 'governorGloss': '说', 'dependent': 1, 'dependentGloss': '奥巴马'}, {'dep': 'det', 'governor': 5, 'governorGloss': '事情', 'dependent': 3, 'dependentGloss': '这个'}, {'dep': 'mark:clf', 'governor': 3, 'governorGloss': '这个', 'dependent': 4, 'dependentGloss': '种'}, {'dep': 'nsubj', 'governor': 8, 'governorGloss': '浪费', 'dependent': 5, 'dependentGloss': '事情'}, {'dep': 'advmod', 'governor': 8, 'governorGloss': '浪费', 'dependent': 6, 'dependentGloss': '怎么'}, {'dep': 'aux:modal', 'governor': 8, 'governorGloss': '浪费', 'dependent': 7, 'dependentGloss': '可以'}, {'dep': 'ccomp', 'governor': 2, 'governorGloss': '说', 'dependent': 8, 'dependentGloss': '浪费'}, {'dep': 'advmod', 'governor': 10, 'governorGloss': '多', 'dependent': 9, 'dependentGloss': '这么'}, {'dep': 'amod', 'governor': 11, 'governorGloss': '时间', 'dependent': 10, 'dependentGloss': '多'}, {'dep': 'dobj', 'governor': 8, 'governorGloss': '浪费', 'dependent': 11, 'dependentGloss': '时间'}, {'dep': 'punct', 'governor': 2, 'governorGloss': '说', 'dependent': 12, 'dependentGloss': '。'}], 'enhancedDependencies': [{'dep': 'ROOT', 'governor': 0, 'governorGloss': 'ROOT', 'dependent': 2, 'dependentGloss': '说'}, {'dep': 'nsubj', 'governor': 2, 'governorGloss': '说', 'dependent': 1, 'dependentGloss': '奥巴马'}, {'dep': 'det', 'governor': 5, 'governorGloss': '事情', 'dependent': 3, 'dependentGloss': '这个'}, {'dep': 'mark:clf', 'governor': 3, 'governorGloss': '这个', 'dependent': 4, 'dependentGloss': '种'}, {'dep': 'nsubj', 'governor': 8, 'governorGloss': '浪费', 'dependent': 5, 'dependentGloss': '事情'}, {'dep': 'advmod', 'governor': 8, 'governorGloss': '浪费', 'dependent': 6, 'dependentGloss': '怎么'}, {'dep': 'aux:modal', 'governor': 8, 'governorGloss': '浪费', 'dependent': 7, 'dependentGloss': '可以'}, {'dep': 'ccomp', 'governor': 2, 'governorGloss': '说', 'dependent': 8, 'dependentGloss': '浪费'}, {'dep': 'advmod', 'governor': 10, 'governorGloss': '多', 'dependent': 9, 'dependentGloss': '这么'}, {'dep': 'amod', 'governor': 11, 'governorGloss': '时间', 'dependent': 10, 'dependentGloss': '多'}, {'dep': 'dobj', 'governor': 8, 'governorGloss': '浪费', 'dependent': 11, 'dependentGloss': '时间'}, {'dep': 'punct', 'governor': 2, 'governorGloss': '说', 'dependent': 12, 'dependentGloss': '。'}], 'enhancedPlusPlusDependencies': [{'dep': 'ROOT', 'governor': 0, 'governorGloss': 'ROOT', 'dependent': 2, 'dependentGloss': '说'}, {'dep': 'nsubj', 'governor': 2, 'governorGloss': '说', 'dependent': 1, 'dependentGloss': '奥巴马'}, {'dep': 'det', 'governor': 5, 'governorGloss': '事情', 'dependent': 3, 'dependentGloss': '这个'}, {'dep': 'mark:clf', 'governor': 3, 'governorGloss': '这个', 'dependent': 4, 'dependentGloss': '种'}, {'dep': 'nsubj', 'governor': 8, 'governorGloss': '浪费', 'dependent': 5, 'dependentGloss': '事情'}, {'dep': 'advmod', 'governor': 8, 'governorGloss': '浪费', 'dependent': 6, 'dependentGloss': '怎么'}, {'dep': 'aux:modal', 'governor': 8, 'governorGloss': '浪费', 'dependent': 7, 'dependentGloss': '可以'}, {'dep': 'ccomp', 'governor': 2, 'governorGloss': '说', 'dependent': 8, 'dependentGloss': '浪费'}, {'dep': 'advmod', 'governor': 10, 'governorGloss': '多', 'dependent': 9, 'dependentGloss': '这么'}, {'dep': 'amod', 'governor': 11, 'governorGloss': '时间', 'dependent': 10, 'dependentGloss': '多'}, {'dep': 'dobj', 'governor': 8, 'governorGloss': '浪费', 'dependent': 11, 'dependentGloss': '时间'}, {'dep': 'punct', 'governor': 2, 'governorGloss': '说', 'dependent': 12, 'dependentGloss': '。'}], 'entitymentions': [{'docTokenBegin': 0, 'docTokenEnd': 1, 'tokenBegin': 0, 'tokenEnd': 1, 'text': '奥巴马', 'characterOffsetBegin': 0, 'characterOffsetEnd': 3, 'ner': 'PERSON'}, {'docTokenBegin': 9, 'docTokenEnd': 10, 'tokenBegin': 9, 'tokenEnd': 10, 'text': '多', 'characterOffsetBegin': 17, 'characterOffsetEnd': 18, 'ner': 'NUMBER'}], 'tokens': [{'index': 1, 'word': '奥巴马', 'originalText': '奥巴马', 'lemma': '奥巴马', 'characterOffsetBegin': 0, 'characterOffsetEnd': 3, 'pos': 'NR', 'ner': 'PERSON'}, {'index': 2, 'word': '说', 'originalText': '说', 'lemma': '说', 'characterOffsetBegin': 3, 'characterOffsetEnd': 4, 'pos': 'VV', 'ner': 'O'}, {'index': 3, 'word': '这个', 'originalText': '这个', 'lemma': '这个', 'characterOffsetBegin': 4, 'characterOffsetEnd': 6, 'pos': 'DT', 'ner': 'O'}, {'index': 4, 'word': '种', 'originalText': '种', 'lemma': '种', 'characterOffsetBegin': 6, 'characterOffsetEnd': 7, 'pos': 'M', 'ner': 'O'}, {'index': 5, 'word': '事情', 'originalText': '事情', 'lemma': '事情', 'characterOffsetBegin': 7, 'characterOffsetEnd': 9, 'pos': 'NN', 'ner': 'O'}, {'index': 6, 'word': '怎么', 'originalText': '怎么', 'lemma': '怎么', 'characterOffsetBegin': 9, 'characterOffsetEnd': 11, 'pos': 'AD', 'ner': 'O'}, {'index': 7, 'word': '可以', 'originalText': '可以', 'lemma': '可以', 'characterOffsetBegin': 11, 'characterOffsetEnd': 13, 'pos': 'VV', 'ner': 'O'}, {'index': 8, 'word': '浪费', 'originalText': '浪费', 'lemma': '浪费', 'characterOffsetBegin': 13, 'characterOffsetEnd': 15, 'pos': 'VV', 'ner': 'O'}, {'index': 9, 'word': '这么', 'originalText': '这么', 'lemma': '这么', 'characterOffsetBegin': 15, 'characterOffsetEnd': 17, 'pos': 'AD', 'ner': 'O'}, {'index': 10, 'word': '多', 'originalText': '多', 'lemma': '多', 'characterOffsetBegin': 17, 'characterOffsetEnd': 18, 'pos': 'CD', 'ner': 'NUMBER'}, {'index': 11, 'word': '时间', 'originalText': '时间', 'lemma': '时间', 'characterOffsetBegin': 18, 'characterOffsetEnd': 20, 'pos': 'NN', 'ner': 'O'}, {'index': 12, 'word': '。', 'originalText': '。', 'lemma': '。', 'characterOffsetBegin': 20, 'characterOffsetEnd': 21, 'pos': 'PU', 'ner': 'O'}]}\n"
     ]
    }
   ],
   "source": [
    "# coding: utf8\n",
    "print(ann['sentences'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not Sentence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-04565322cc3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not Sentence"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
